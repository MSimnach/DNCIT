---
title: "Example: Pediatric ultrasonic images and electronic health records"
output: html_document
bibliography: "`r fs::path_package('references.bib', package='DNCIT')`" 
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

We apply the deep nonparametric conditional independence test (DNCIT) to pediatric ultrasonic images and electronic health records from the dataset in @Marcinkevics2023. This will illustrate an intermediate example to medical images and showcase potential challenges as well as research questions. 

The DNCIT tests for conditional associations between an image and a scalar outcome, given a vector-valued confounder. Thereby, different research questions can be addressed, with some examples being:

* Does the image contain additional information about the diagnosis, given electronic health records (EHRs)? 
* Is a specific EHR a potential confounder of the image, given other EHRs? 

In general, the DNCIT is developed for data consisting of $n$ i.i.d. copies of an image $X$, a scalar $Y$ and, potentially, a vector-valued confounder $Z$. The main challenge to apply the `DNCIT()` function is to input the data in the correct format, which is especially important for images. There are two important cases between which we differentiate: 

* Feature representations of the observed images are already available should be used in the test.
* The raw images are available and feature representations should be computed by a default embedding map of the package.

We discuss both scenarios separately in the following two sections, targeting the research questions above. Our dataset consists of a subset of the 572 pediatric ultrasonic images and tabular electronic health records. Additionally, we obtained preprocessed feature representations of the images.

```{r setup}
library(DNCIT)
if (requireNamespace("fs")){
  library(fs)
}else{
  install.packages('fs')
  library(fs)
}
```

### Preprocessing 

You can skip this section, if you are not interested in the data preprocessing. In our example, the tabular data is saved as a python dictionary, which can be loaded into R as a list:


```{r meta data}
pediatric_data_path <- fs::path_package("extdata/example_pediatric_patients", package = "DNCIT")
meta_data_path <- paste(pediatric_data_path, 'app_data', sep='/')
meta_data_dict <- readLines(meta_data_path)
json <- reticulate::import('json')
meta_data <- json$loads(meta_data_dict)
head(meta_data,1)
```

So far, the tabular data consists for each subject (here subject with id 61) of the file names of the images in [[1]], the diagnosis of the patient in [[2]], tabular data in [[3]] and [[4]]. The tabular data in [[3]] consists of general, score, clinical, laboratory and image-derived features: 
```{r, echo=FALSE}
EHRs <- c('Age', 'Sex', 'Height', 'Weight', 'BMI', 'Alvarado_Score', 'Paedriatic_Appendicitis_Score',
'Peritonitis', 'Migratory_Pain', 'Lower_Right_Abd_Pain', 'Contralateral_Rebound_Tenderness', 'Coughing_Pain', 'Psoas_Sign', 'Nausea', 'Loss_of_Appetite', 'Body_Temperature', 'Dysuria', 'Stool', 'WBC_Count', 'Neutrophil_Percentage', 'CRP', 'Ketones_in_Urine', 'RBC_in_Urine',                'WBC_in_Urine', 'Appendix_on_US', 'Appendix_Diameter', 'Free_Fluids',  'Appendix_Wall_Layers', 'Target_Sign', 'Perfusion', 'Perforation', 
'Surrounding_Tissue_Reaction', 'Pathological_Lymph_Nodes', 'Bowel_Wall_Thickening', 'Ileus', 'Coprostasis', 'Meteorism', 'Enteritis', 'Appendicular_Abscess', 'Conglomerate_of_Bowel_Loops', 'Gynecological_Findings')
others <- c('Age', 'Sex', 'Height', 'Weight', 'BMI', 'Length_of_Stay')
others <- others[others %in% EHRs]
scores <- c('Alvarado_Score', 'Paedriatic_Appendicitis_Score')
scores <- scores[scores %in% EHRs]
clinical <- c('Peritonitis', 'Migratory_Pain', 'Lower_Right_Abd_Pain', 'Contralateral_Rebound_Tenderness', 'Ipsilateral_Rebound_Tenderness', 'Coughing_Pain', 'Psoas_Sign', 'Nausea', 'Loss_of_Appetite', 'Body_Temperature', 'Dysuria', 'Stool')
clinical <- clinical[clinical %in% EHRs]
lab <- c('WBC_Count', 'Neutrophil_Percentage', 'CRP', 'Ketones_in_Urine', 'RBC_in_Urine', 'WBC_in_Urine') 
lab <- lab[lab %in% EHRs]
ultrasound <- c('Appendix_on_US', 'Appendix_Diameter', 'Free_Fluids',  'Appendix_Wall_Layers', 'Target_Sign', 'Perfusion', 'Perforation', 'Surrounding_Tissue_Reaction', 'Pathological_Lymph_Nodes', 'Bowel_Wall_Thickening', 'Ileus', 'Coprostasis', 'Meteorism', 'Enteritis', 'Appendicular_Abscess', 'Conglomerate_of_Bowel_Loops', 'Gynecological_Findings') 
ultrasound <- ultrasound[ultrasound %in% EHRs]
non_ultrasound <- c(lab[lab %in% EHRs], clinical[clinical %in% EHRs], scores[scores %in% EHRs], others[others %in% EHRs])
cat('General features: ', paste(others, collapse=" "), '\n',
    'Scores: ', paste(scores, collapse=" "), '\n',
    'Clinical: ', paste(clinical, collapse=" "), '\n',
    'Laboratory: ', paste(lab, collapse=" "), '\n',
    'Image derived: ', paste(ultrasound, collapse=" "), '\n', sep = '')
```
The image derived features are expert-produced ultrasonic features. The function `DNCIT()` requires the scalar $Y$ as well as the conditioning variables $Z$ as matrix inputs. Thus, we convert the diagnosis and all EHRs to matrices

```{r construct Z and Y}
Y <- matrix(NA, nrow = length(meta_data), ncol = 1, dimnames = list(names(meta_data),NULL))
for (id in names(meta_data)){
  Y[id,] <- meta_data[id][[id]][[2]]
}
p <- length(meta_data$'61'[[3]])
EHR_mat <- matrix(NA, nrow = length(meta_data), ncol = p, dimnames = list(names(meta_data),EHRs))
for (id in names(meta_data)){
  EHR_mat[id,] <- meta_data[id][[id]][[3]]
}
EHR_non_US <- EHR_mat[, non_ultrasound, drop=FALSE]
EHR_US <- EHR_mat[, ultrasound, drop=FALSE]
EHR_others <- EHR_mat[, others, drop=FALSE]
print('First five entries of diagnoses: ')
print(head(Y,5))
print('First five entries of EHRs: ')
print(head(EHR_mat,5))
```

The ids of the subjects can be provided as row names in $Y$ and $Z$. Thereby, we can match them with the given feature representations in $X$. For example, this is done automatically in the `DNCIT()` function for feature representations loaded from a .npz file. For the feature representations, the only thing that has to be provided is the directory of the .npz file.

## DNCITs applied directly to images

It can happen that there are no feature representations available. Applying the implemented CITs directly to the images is not possible since are not able to handle the dimension of the image and either do not compute in reasonable time or produce unreliable results. As a solution, we propose in the paper to apply first a dimension reduction to the images and afterwards an existing CIT. Therefore, the `DNCIT()` function takes a pre-specified embedding map, computes corresponding feature representations for the images and applies a CIT of our choice to the feature representations.

The package provides general default dimension reduction methods. This article applies the tucker decomposition from the package `vignette('rTensor')` adjusted to our setting in the function `tucker_decomposition()`. The function can be either applied to images loaded already as array or to a path of a directory with .png images. Usually, we recommend to first process the images and save the feature representations, and afterwards apply a CIT with these feature representations. The feature representations of the Tucker decomposition can be obtained by:

```{r}
img_path <- paste(pediatric_data_path, 'ultrasonic_images/', sep='/')
# if(requireNamespace("progressr", quietly = TRUE)){
#    progressr::with_progress(X <- tucker_decomposition(img_dir_path=img_path))
# }else{
#    features_tucker <- tucker_decomposition(img_dir_path=img_path)
# } 
features_tucker_path <- paste(pediatric_data_path, 'features_tucker', 'features_tucker.RData', sep='/')
#save(features_tucker, file = features_tucker_path)
```

Usually, we would choose a suitable (nonparametric) CIT before the application of the DNCIT, depending on the sample size, dimension of the feature representations as well as of the confounder and the computational costs. Throughout this article, we select the RCOT from @strobl2019approximate as CIT. We specify the CIT and its parameters in [cit_with_parameters], here by cit_with_parameters['cit']='RCOT' and cit_with_parameters['seed']=123, which is also the default option in `DNCIT()`. We take always the median of 20 runs of the RCOT, since the test is depending on a random seed.

### Conditional association between image and diagnosis given all EHRs

First, we study if the image contains additional information about the diagnosis, given all available EHRs? To test if the ultrasonic image contains additional information for the diagnosis after accounting for all information available in the EHRs, we test for conditional associations between the images and the diagnosis given the EHRs with `DNCIT()` applied to image-derived features in $X$ and the diagnosis in $Y$, given other EHRs in $Z$. The parameters to load the feature representations are given in a list [embedding_map_with_parameters], where we specify that we have already derived and loaded feature representations by embedding_map_with_parameters='feature_representations'. Furthermore, 

```{r image data}
# features are loaded as features_tucker
load(features_tucker_path)
#order rows of X according to Y and Z
img_files <- list.files(img_path)
ids_imgs <- gsub("(\\d+)\\..*", "\\1", img_files)
row.names(features_tucker) <- ids_imgs

embedding_map_with_parameters <- list(embedding_map = 'feature_representations')
#RCoT
seeds=1:20
res <- rep(1, 20)
for(seed in seeds){
  cit_with_parameters <- list(cit = 'RCOT', params_cit = list(seed=seed))
  res[seed] <- DNCIT(features_tucker, Y, Z=EHR_mat,embedding_map_with_parameters = embedding_map_with_parameters, cit_with_parameters = cit_with_parameters)$p
}
print(median(res))
```

The `DNCIT()` function outputs the test statistic, p-value and runtime of the RCOT applied to the feature representations. The p-value of `r median(res)` implies that the image contains "weakly" significant additional information about the diagnosis, given all available EHRs. 

### Information between image and diagnosis given non-image-derived EHRs

The above result of a relatively high p-value can have many reasons, one being that image-derived EHRs in $Z$ are produced through experts from the image. Thus, they can be seen as mediator, taking away the relevant information within the image for the diagnosis. We want to check for this and run the test in a next step only on the image and non-image-derived EHRs: 

```{r Z without image-derived EHRs}
EHR_non_img <- EHR_mat[, non_ultrasound, drop=FALSE]
#RCoT
seeds=1:20
res <- rep(1, 20)
for(seed in seeds){
  cit_with_parameters <- list(cit = 'RCOT', params_cit = list(seed=seed))
  res[seed] <- DNCIT(features_tucker, Y, Z=EHR_non_img, embedding_map_with_parameters = embedding_map_with_parameters, cit_with_parameters = cit_with_parameters)$p
}
median(res)
```

We observe that the median over the p-values is now lower. Particularly, at a significant level of $0.005$ the image now contains significant information on the diagnosis, after accounting for the non-image derived EHRs. 

### Potential confounder of the image

Next, we are interested in a somewhat different question. Often, it is advantageous w.r.t. power, type 1 error and runtime to include less confounder for a CIT. However, if relevant confounder, i.e. variables with causal effects on image and diagnosis, are not included, the CIT might reject the null hypothesis of conditional independence although the only association between image and the diagnosis is through the left-out confounder. 

To check if a variable in the data may be a confounder and should be included in $Z$, it should be conditionally associated with the image, given all other confounder. We showcase this for the laboratory EHRs, given all general EHRs as well as for the clinical EHRs, given all general EHRs:
```{r laboratory EHRs as confounder}
EHR_lab <- EHR_mat[, lab, drop=FALSE]
EHR_others <- EHR_mat[, others, drop=FALSE]
EHR_clinical <- EHR_mat[, clinical, drop=FALSE]
#RCoT
#lab
seeds=1:20
res_lab_confound <- rep(1, 20)
for(seed in seeds){
  cit_with_parameters <- list(cit = 'RCOT', params_cit = list(seed=seed))
  res_lab_confound[seed] <- DNCIT(features_tucker, Y=EHR_lab, Z=EHR_others, embedding_map_with_parameters = embedding_map_with_parameters, cit_with_parameters = cit_with_parameters)$p
}
#clinical
seeds=1:20
res_clinical_confound <- rep(1, 20)
for(seed in seeds){
  cit_with_parameters <- list(cit = 'RCOT', params_cit = list(seed=seed))
  res_clinical_confound[seed] <- DNCIT(features_tucker, Y=EHR_clinical, Z=EHR_others, embedding_map_with_parameters = embedding_map_with_parameters, cit_with_parameters = cit_with_parameters)$p
}
cat('Median p-value laboratory EHRs: ', median(res_lab_confound), '\n',
    'Median p-value clinical EHRs: ', median(res_clinical_confound), '\n', sep="")
```
Depending on the p-values, the set of clinical EHRs tend to be more relevant as confounder for the image, given the general EHRs, compared to the laboratory EHRs. While we would often rather test only for one of the clinical and laboratory EHRs at the same time, the example illustrates another interesting feature of the DNCITs: $Y$ does not necessarily have to be a scalar, as long as the implemented CITs allow for non-scalar $Y$ as the RCOT does.

## DNCIT applied to available feature representations

This section discusses the scenario where feature representations of the images are already available. In our case, we use the expert-produced features from the images as low-dimensional feature representations, assuming they contain the important information of the image for the diagnosis.

### Information between image and diagnosis given all non-image EHRs

```{r DNCIT applied to feature representations}
EHR_non_img <- EHR_mat[, non_ultrasound, drop=FALSE]
EHR_img <- EHR_mat[, ultrasound, drop=FALSE]

embedding_map_with_parameters <- 'feature_representations'
#RCoT
seeds=1:20
res <- rep(1, 20)
for(seed in seeds){
  cit_with_parameters <- list(cit = 'RCOT', params_cit = list(seed=seed))
  res[seed] <- DNCIT(EHR_img, Y, Z=EHR_non_img, embedding_map_with_parameters = embedding_map_with_parameters, cit_with_parameters = cit_with_parameters)$p
}
print(median(res))
```

We see, that the expert-produced feature representations of the images contain significant information about the diagnosis, given all non-image EHRs. This is in line with the result of the Tucker decomposition, given all non-image EHRs. 
```{r alternative CITs, include=FALSE}
#results <- matrix(NA, nrow=3, ncol=5, dimnames = list(c('Test Statistic', 'P-Value', 'Runtime'), c('RCOT', 'cpt_kpc', 'cmiknn', 'fcit', 'gcm')))
#results[, 'RCOT'] <- c(res$Sta, res$p, res$runtime)
#cpt_kpc
#cit_with_parameters <- list(cit = 'cpt_kpc', params_cit = list(k=kernlab::rbfdot(1/(2 * stats::median(stats::dist(Y))^2)),  Knn=10, model.formula.YZ='V1~V2+V3'))
#res <- DNCIT(X, Y, Z, embedding_map_with_parameters = embedding_map_with_parameters, cit_with_parameters = cit_with_parameters)
#results[, 'cpt_kpc'] <- c(res$Sta, res$p, res$runtime)
#cmiknn
#cit_with_parameters <- list(cit = 'cmiknn', params_cit = list(knn=0.2))
#res <- DNCIT(X, Y, Z, embedding_map_with_parameters = embedding_map_with_parameters, cit_with_parameters = cit_with_parameters)
#results[, 'cmiknn'] <- c(res$Sta, res$p, res$runtime)
#fcit
#cit_with_parameters <- list(cit = 'fcit')
#res <- DNCIT(X, Y, Z, embedding_map_with_parameters = embedding_map_with_parameters, cit_with_parameters = cit_with_parameters)
#results[, 'fcit'] <- c(res$Stat, res$p, res$runtime)
#gcm
#cit_with_parameters <- list(cit = 'gcm')
#res <- DNCIT(X, Y, Z, embedding_map_with_parameters = embedding_map_with_parameters, cit_with_parameters = cit_with_parameters)
#results[, 'gcm'] <- c(res$Sta, res$p, res$runtime)
```

## References
